{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import scanpy.external as sce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.stats import percentileofscore\n",
    "import warnings\n",
    "import logging\n",
    "import sys\n",
    "import bbknn\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "sc.settings.verbosity = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk_path='/private/groups/russelllab/jodie/wolbachia_induced_DE/scanpy_clustering/scanpy_objects/bulk_adata.h5ad'\n",
    "# ref_path='/private/groups/russelllab/jodie/wolbachia_induced_DE/scanpy_clustering/scanpy_objects/blood_adata.h5ad'\n",
    "# output_dir='/private/groups/russelllab/jodie/wolbachia_induced_DE/wolbachia_induced_differentiation/scripts/celltype_clustering/claude/MNN_kNN_tree/blood_atlas'\n",
    "# annotation_key='subclustering'\n",
    "# k_neighbors=None\n",
    "# num_permutations=1000\n",
    "# seed=42\n",
    "\n",
    "bulk_path='/private/groups/russelllab/jodie/wolbachia_induced_DE/scanpy_clustering/scanpy_objects/bulk_adata.h5ad'\n",
    "ref_path='/private/groups/russelllab/jodie/wolbachia_induced_DE/scanpy_clustering/scanpy_objects/combined_germline_sg_trachea.h5ad'\n",
    "output_dir='/private/groups/russelllab/jodie/wolbachia_induced_DE/wolbachia_induced_differentiation/scripts/celltype_clustering/claude/MNN_kNN_tree/embryo_atlas_germline'\n",
    "annotation_key='subtypes'\n",
    "k_neighbors=None\n",
    "num_permutations=1000\n",
    "seed=42\n",
    "mem = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color map to match final figures\n",
    "color_dict={\n",
    "    'JW18DOX':'#87de87', # green\n",
    "    'JW18wMel':'#00aa44',  # dark green\n",
    "    'S2DOX':'#ffb380', # orange\n",
    "    'S2wMel':'#d45500' # dark orange\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set up output directory and plotting parameters.\"\"\"\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "plots_dir = os.path.join(output_dir, 'plots')\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Set up log file\n",
    "log_file = os.path.join(output_dir, 'integration_log.txt')\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Set scanpy settings\n",
    "sc.settings.figdir = plots_dir\n",
    "sc.settings.set_figure_params(dpi=300, frameon=False, figsize=(10, 8), facecolor='white')\n",
    "\n",
    "# Define custom color palette for cell types\n",
    "# custom_palette = sns.color_palette(\"husl\", 100)  # Generate a large color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_validate_data(bulk_path, ref_path):\n",
    "    \"\"\"Load and validate input AnnData objects.\"\"\"\n",
    "    logger.info(\"Loading data files...\")\n",
    "    \n",
    "    # Load bulk data\n",
    "    try:\n",
    "        bulk_adata = sc.read_h5ad(bulk_path)\n",
    "        logger.info(f\"Bulk dataset loaded: {bulk_adata.shape} (samples × genes)\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading bulk data: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Load reference data\n",
    "    try:\n",
    "        ref_adata = sc.read_h5ad(ref_path)\n",
    "        logger.info(f\"Reference dataset loaded: {ref_adata.shape} (cells × genes)\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading reference data: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Ensure unique gene names\n",
    "    bulk_adata.var_names_make_unique()\n",
    "    ref_adata.var_names_make_unique()\n",
    "    \n",
    "    # Check for shared genes\n",
    "    shared_genes = bulk_adata.var_names.intersection(ref_adata.var_names)\n",
    "    if len(shared_genes) == 0:\n",
    "        logger.error(\"No shared genes between bulk and reference datasets!\")\n",
    "        raise ValueError(\"No shared genes between datasets\")\n",
    "    else:\n",
    "        logger.info(f\"Number of shared genes: {len(shared_genes)}\")\n",
    "    \n",
    "    return bulk_adata, ref_adata\n",
    "\n",
    "\n",
    "def preprocess_data(bulk_adata, ref_adata, annotation_key):\n",
    "    \"\"\"Preprocess AnnData objects and prepare for integration.\"\"\"\n",
    "    logger.info(\"Preprocessing datasets...\")\n",
    "    \n",
    "    # Make copies to avoid modifying the originals\n",
    "    bulk = bulk_adata.copy()\n",
    "    ref = ref_adata.copy()\n",
    "    \n",
    "    # Add dataset labels for batch correction\n",
    "    bulk.obs[\"dataset\"] = \"bulk\"\n",
    "    ref.obs[\"dataset\"] = \"reference\"\n",
    "    \n",
    "    # Find shared genes\n",
    "    shared_genes = bulk.var_names.intersection(ref.var_names)\n",
    "    logger.info(f\"Using {len(shared_genes)} shared genes\")\n",
    "    \n",
    "    # Subset to shared genes\n",
    "    bulk_subset = bulk[:, shared_genes].copy()\n",
    "    ref_subset = ref[:, shared_genes].copy()\n",
    "    \n",
    "    # Check if annotation key exists in reference data\n",
    "    if annotation_key not in ref_subset.obs.columns:\n",
    "        logger.error(f\"Annotation key '{annotation_key}' not found in reference data.\")\n",
    "        available_keys = list(ref_subset.obs.columns)\n",
    "        logger.error(f\"Available keys: {available_keys}\")\n",
    "        raise KeyError(f\"Annotation key '{annotation_key}' not found in reference data\")\n",
    "    \n",
    "    return bulk_subset, ref_subset\n",
    "\n",
    "\n",
    "def integrate_datasets(bulk_adata, ref_adata):\n",
    "    \"\"\"Integrate bulk and single-cell datasets.\"\"\"\n",
    "    logger.info(\"Integrating datasets...\")\n",
    "    \n",
    "    # Concatenate datasets\n",
    "    combined = ad.concat([ref_adata, bulk_adata], join=\"outer\", merge=\"first\")\n",
    "    logger.info(f\"Combined dataset shape: {combined.shape}\")\n",
    "    \n",
    "    # Since data is already normalized and log-transformed, we skip those steps\n",
    "    logger.info(\"Data is already normalized and log-transformed\")\n",
    "    \n",
    "    # Ensure no NaN values that could cause issues\n",
    "    if sparse.issparse(combined.X):\n",
    "        combined.X = sparse.csr_matrix(np.nan_to_num(combined.X.toarray(), nan=0, posinf=0, neginf=0))\n",
    "    else:\n",
    "        combined.X = np.nan_to_num(combined.X, nan=0, posinf=0, neginf=0)\n",
    "    \n",
    "    # # # Apply BBKNN batch correction\n",
    "    # logger.info(\"Applying BBKNN batch correction...\")\n",
    "    # # Perform batch correction with BBKNN\n",
    "    # bbknn.bbknn(combined, batch_key='dataset')\n",
    "\n",
    "    # Apply batch correction using MNN\n",
    "    logger.info(\"Applying MNN batch correction...\")\n",
    "    try:\n",
    "        corrected = sce.pp.mnn_correct(combined, batch_key=\"dataset\", return_only_var_genes=False)\n",
    "        # MNN returns a tuple with the corrected AnnData as the first element\n",
    "        corrected_adata = corrected[0]\n",
    "        logger.info(\"MNN batch correction completed\")\n",
    "        print(type(corrected_adata))\n",
    "        return corrected_adata\n",
    "    except Exception as e:\n",
    "        logger.error(f\"MNN batch correction failed: {e}\")\n",
    "        logger.warning(\"Continuing without batch correction\")\n",
    "        return combined\n",
    "    # return combined\n",
    "    \n",
    "\n",
    "def compute_p_value(neighbor_labels, assigned_label, k, num_permutations=1000):\n",
    "    \"\"\"\n",
    "    Compute p-value by shuffling labels and checking how often\n",
    "    the assigned label appears by chance.\n",
    "    \"\"\"\n",
    "    # Convert to numpy array for efficient operations\n",
    "    neighbor_labels = np.array(neighbor_labels)\n",
    "    simulated_counts = []\n",
    "    \n",
    "    for _ in range(num_permutations):\n",
    "        shuffled_labels = np.random.permutation(neighbor_labels)\n",
    "        simulated_counts.append((shuffled_labels == assigned_label).sum() / k)\n",
    "    \n",
    "    observed_prob = (neighbor_labels == assigned_label).sum() / k\n",
    "    p_value = (100 - percentileofscore(simulated_counts, observed_prob)) / 100\n",
    "    \n",
    "    return p_value\n",
    "\n",
    "\n",
    "def determine_optimal_k(ref_adata, annotation_key):\n",
    "    \"\"\"Determine the optimal k value for kNN classification.\"\"\"\n",
    "    num_ref_cells = ref_adata.shape[0]\n",
    "    \n",
    "    # Get the size of the smallest class\n",
    "    try:\n",
    "        min_class_size = ref_adata.obs[annotation_key].value_counts().min()\n",
    "    except:\n",
    "        logger.warning(\"Could not compute min class size, using default\")\n",
    "        min_class_size = 100\n",
    "    \n",
    "    # Calculate potential k values:\n",
    "    # 1. Square root of number of reference cells\n",
    "    # 2. 10% of smallest class size\n",
    "    k_sqrt = int(np.sqrt(num_ref_cells))\n",
    "    k_10pct = int(min_class_size * 0.1)\n",
    "    \n",
    "    # Use the smaller of the two values, but ensure k is at least 5\n",
    "    k = max(5, min(k_sqrt, k_10pct))\n",
    "    \n",
    "    logger.info(f\"Automatically determined k = {k} (sqrt(n) = {k_sqrt}, 10% of smallest class = {k_10pct})\")\n",
    "    \n",
    "    return k\n",
    "\n",
    "\n",
    "# def kNN_classifier(combined_adata, ref_label_key, k, num_permutations=1000):\n",
    "#     \"\"\"\n",
    "#     Classify bulk cells based on their k nearest neighbors in the reference dataset.\n",
    "#     \"\"\"\n",
    "#     logger.info(f\"Performing kNN classification with k={k}...\")\n",
    "    \n",
    "#     # Identify reference and bulk cells\n",
    "#     ref_indices = combined_adata.obs[\"dataset\"] == \"reference\"\n",
    "#     bulk_indices = combined_adata.obs[\"dataset\"] == \"bulk\"\n",
    "    \n",
    "#     # Get indices as arrays\n",
    "#     ref_idx = np.where(ref_indices)[0]\n",
    "#     bulk_idx = np.where(bulk_indices)[0]\n",
    "    \n",
    "#     logger.info(f\"Reference cells: {len(ref_idx)}, Bulk samples: {len(bulk_idx)}\")\n",
    "    \n",
    "#     # Extract data for classification\n",
    "#     try:\n",
    "#         # Handle sparse matrices if needed\n",
    "#         if sparse.issparse(combined_adata.X):\n",
    "#             X_ref = combined_adata.X[ref_idx].toarray()\n",
    "#             X_bulk = combined_adata.X[bulk_idx].toarray()\n",
    "#         else:\n",
    "#             X_ref = combined_adata.X[ref_idx]\n",
    "#             X_bulk = combined_adata.X[bulk_idx]\n",
    "        \n",
    "#         # Handle any NaNs or infs\n",
    "#         X_ref = np.nan_to_num(X_ref, nan=0, posinf=0, neginf=0)\n",
    "#         X_bulk = np.nan_to_num(X_bulk, nan=0, posinf=0, neginf=0)\n",
    "        \n",
    "#         # Build kd-tree for efficient nearest neighbor search\n",
    "#         tree = cKDTree(X_ref)\n",
    "#         distances, neighbor_idx = tree.query(X_bulk, k=k)\n",
    "        \n",
    "#         # Get reference cell labels\n",
    "#         ref_labels = combined_adata.obs.loc[ref_indices, ref_label_key].values\n",
    "        \n",
    "#         results = []\n",
    "#         for i, (dists, neighbors) in enumerate(zip(distances, neighbor_idx)):\n",
    "#             # Get labels of k nearest neighbors\n",
    "#             neighbor_labels = ref_labels[neighbors]\n",
    "            \n",
    "#             # Determine the most frequent label (majority vote)\n",
    "#             unique_labels, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "#             assigned_label = unique_labels[np.argmax(counts)]\n",
    "#             max_count = counts[np.argmax(counts)]\n",
    "            \n",
    "#             # Calculate confidence score (percentage of neighbors with the assigned label)\n",
    "#             confidence = max_count / k\n",
    "            \n",
    "#             # Compute p-value with permutation test\n",
    "#             p_value = compute_p_value(neighbor_labels, assigned_label, k, num_permutations)\n",
    "            \n",
    "#             # Store results\n",
    "#             results.append({\n",
    "#                 \"Bulk_Sample\": combined_adata.obs.index[bulk_idx[i]],\n",
    "#                 \"Predicted_Label\": assigned_label,\n",
    "#                 \"Confidence\": confidence,\n",
    "#                 \"P_value\": p_value,\n",
    "#                 \"Nearest_Neighbors\": list(combined_adata.obs.index[ref_idx[neighbors]]),\n",
    "#                 \"Neighbor_Labels\": list(neighbor_labels),\n",
    "#                 \"Neighbor_Distances\": list(dists)\n",
    "#             })\n",
    "        \n",
    "#         # Create results DataFrame\n",
    "#         results_df = pd.DataFrame(results)\n",
    "        \n",
    "#         # Add predicted labels to the combined dataset\n",
    "#         for i, idx in enumerate(bulk_idx):\n",
    "#             combined_adata.obs.loc[combined_adata.obs.index[idx], ref_label_key] = results_df.iloc[i][\"Predicted_Label\"]\n",
    "        \n",
    "#         logger.info(\"kNN classification completed\")\n",
    "#         return results_df, combined_adata\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"kNN classification failed: {e}\")\n",
    "#         import traceback\n",
    "#         logger.error(traceback.format_exc())\n",
    "#         raise\n",
    "\n",
    "\n",
    "\n",
    "# kNN-based classification\n",
    "def kNN_classifier_with_stats(combined_adata, ref_label_key, k):\n",
    "    \"\"\"\n",
    "    Classifies unknown cells based on their k nearest neighbors in the reference dataset.\n",
    "    Reports neighbor indices, distances, cell type assignments, and statistical confidence.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with predicted labels, neighbor information, and z-scores.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Performing kNN-based classification...\")\n",
    "\n",
    "    ref_indices = combined_adata.obs[\"dataset\"] == \"Reference\"\n",
    "    unknown_indices = combined_adata.obs[\"dataset\"] == \"Unknown\"\n",
    "\n",
    "    # Extract gene expression space\n",
    "    X_ref = combined_adata[ref_indices].X.toarray() if hasattr(combined_adata.X, \"toarray\") else combined_adata[ref_indices].X\n",
    "    X_unknown = combined_adata[unknown_indices].X.toarray() if hasattr(combined_adata.X, \"toarray\") else combined_adata[unknown_indices].X\n",
    "\n",
    "    # Construct k-d tree for nearest neighbor searching\n",
    "    tree = cKDTree(X_ref)\n",
    "    distances, indices = tree.query(X_unknown, k=k)\n",
    "\n",
    "    # Retrieve reference cell labels\n",
    "    ref_labels = combined_adata.obs.loc[ref_indices, ref_label_key].values\n",
    "\n",
    "    results = []\n",
    "    for i, (dists, neighbor_indices) in enumerate(zip(distances, indices)):\n",
    "        neighbor_labels = ref_labels[neighbor_indices]\n",
    "        assigned_label = pd.Series(neighbor_labels).mode()[0]\n",
    "\n",
    "        # Compute probability\n",
    "        cell_type_counts = pd.Series(neighbor_labels).value_counts()\n",
    "        expected_prob = cell_type_counts / k\n",
    "        observed_prob = expected_prob.loc[assigned_label]\n",
    "        z_score = (observed_prob - expected_prob.mean()) / expected_prob.std()\n",
    "\n",
    "        # Compute p-value with permutation test\n",
    "        p_value = compute_p_value(neighbor_labels, assigned_label, k)\n",
    "\n",
    "        results.append({\n",
    "            \"Unknown_Cell\": combined_adata.obs.index[unknown_indices][i],\n",
    "            \"Predicted_Label\": assigned_label,\n",
    "            \"Neighbor_Cells\": list(combined_adata.obs.index[ref_indices][neighbor_indices]),\n",
    "            \"Neighbor_Types\": list(neighbor_labels),\n",
    "            \"Distances\": list(dists),\n",
    "            \"Z-score\": z_score,\n",
    "            \"P-value\": p_value\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results), combined_adata\n",
    "\n",
    "def visualize_integration(combined_adata, annotation_key, plots_dir):\n",
    "    \"\"\"Generate UMAP visualizations of the integrated data.\"\"\"\n",
    "    logger.info(\"Generating UMAP visualizations...\")\n",
    "    \n",
    "    # Compute PCA\n",
    "    sc.pp.pca(combined_adata, svd_solver='arpack')\n",
    "    \n",
    "    # Compute neighborhood graph\n",
    "    sc.pp.neighbors(combined_adata, n_neighbors=15, n_pcs=30)\n",
    "    \n",
    "    # Compute UMAP embedding\n",
    "    sc.tl.umap(combined_adata)\n",
    "    \n",
    "    # Save plots\n",
    "    sc.pl.umap(combined_adata, color='dataset', title='Dataset (bulk vs reference)',\n",
    "               save='_dataset.pdf')\n",
    "    \n",
    "    sc.pl.umap(combined_adata, color=annotation_key, title=f'Cell Types ({annotation_key})',\n",
    "               save=f'_{annotation_key}.pdf')\n",
    "    \n",
    "    # Run leiden clustering\n",
    "    sc.tl.leiden(combined_adata, resolution=0.8)\n",
    "    sc.pl.umap(combined_adata, color='leiden', title='Leiden Clusters',\n",
    "               save='_leiden.pdf')\n",
    "    \n",
    "    # Create a custom plot highlighting bulk samples\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Plot reference cells in gray\n",
    "    ref_mask = combined_adata.obs['dataset'] == 'reference'\n",
    "    ax.scatter(\n",
    "        combined_adata.obsm['X_umap'][ref_mask, 0],\n",
    "        combined_adata.obsm['X_umap'][ref_mask, 1],\n",
    "        c='lightgray', s=5, alpha=0.5, label='Reference'\n",
    "    )\n",
    "    \n",
    "    # Plot bulk samples with distinct colors based on their predicted cell type\n",
    "    bulk_mask = combined_adata.obs['dataset'] == 'bulk'\n",
    "    bulk_cell_types = combined_adata.obs.loc[bulk_mask, annotation_key].astype('category')\n",
    "    \n",
    "    for ct in bulk_cell_types.cat.categories:\n",
    "        ct_mask = (combined_adata.obs['dataset'] == 'bulk') & (combined_adata.obs[annotation_key] == ct)\n",
    "        ax.scatter(\n",
    "            combined_adata.obsm['X_umap'][ct_mask, 0],\n",
    "            combined_adata.obsm['X_umap'][ct_mask, 1],\n",
    "            s=100, alpha=0.9, label=f'Bulk - {ct}'\n",
    "        )\n",
    "    \n",
    "    ax.set_title('UMAP - Bulk Samples Highlighted')\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'bulk_samples_highlighted.pdf'), bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    logger.info(\"UMAP visualizations completed\")\n",
    "    \n",
    "    return combined_adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def subsample_celltypes(adata, annotation_key, max_cells_per_type=1000):\n",
    "    \"\"\"Subsample cell types to ensure even representation with a max cap.\"\"\"\n",
    "    # Get the cell type counts\n",
    "    celltype_counts = adata.obs[annotation_key].value_counts()\n",
    "\n",
    "    # Get the minimum cell type count, but cap at max_cells_per_type\n",
    "    min_count = min(celltype_counts.min(), max_cells_per_type)\n",
    "\n",
    "    # Create a list to store the subsampled AnnData objects\n",
    "    subsampled_adatas = []\n",
    "\n",
    "    # Iterate over each cell type\n",
    "    for celltype in celltype_counts.index:\n",
    "        # Get the indices for the current cell type\n",
    "        celltype_indices = adata.obs[annotation_key] == celltype\n",
    "        celltype_idx = np.where(celltype_indices)[0]\n",
    "        \n",
    "        # Determine sample size (minimum of actual count or min_count)\n",
    "        sample_size = min(len(celltype_idx), min_count)\n",
    "        \n",
    "        # Subsample the current cell type\n",
    "        if len(celltype_idx) > sample_size:\n",
    "            chosen_idx = np.random.choice(celltype_idx, sample_size, replace=False)\n",
    "            subset_idx = np.zeros(adata.shape[0], dtype=bool)\n",
    "            subset_idx[chosen_idx] = True\n",
    "            subsampled_adata = adata[subset_idx].copy()\n",
    "        else:\n",
    "            subsampled_adata = adata[celltype_indices].copy()\n",
    "            \n",
    "        # Append the subsampled AnnData object to the list\n",
    "        subsampled_adatas.append(subsampled_adata)\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "\n",
    "    # Concatenate the subsampled AnnData objects\n",
    "    logger.info(f\"Concatenating {len(subsampled_adatas)} subsampled datasets\")\n",
    "    subsampled_adata = ad.concat(subsampled_adatas, join='inner', index_unique='-')\n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del subsampled_adatas\n",
    "    gc.collect()\n",
    "\n",
    "    return subsampled_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_UMAP(combined_adata, annotation):\n",
    "    # Perform UMAP\n",
    "    # neighbors_rank(combined_adata)\n",
    "\n",
    "    # Plot UMAP, save to file\n",
    "    sc.pl.umap(combined_adata, color=['dataset'], save='combine-dataset.pdf')\n",
    "    # Visualization\n",
    "    sc.pl.umap(combined_adata, color=[annotation], save='combined-tissue.pdf')\n",
    "\n",
    "    #Annotate UMAP with larger markers\n",
    "    # Plot the UMAP\n",
    "    sc.pl.umap(combined_adata, color=[annotation], show=False)\n",
    "\n",
    "    # Get the UMAP coordinates\n",
    "    umap_coords = combined_adata.obsm['X_umap']\n",
    "\n",
    "    # Get your sample labels from the data\n",
    "    labels = combined_adata.obs['Sample']\n",
    "\n",
    "    # Iterate over each point and add a label if it's not NA\n",
    "    for idx, label in enumerate(labels):\n",
    "        if pd.notna(label):  # Check if the label is not NA\n",
    "\n",
    "            plt.plot(umap_coords[idx, 0], umap_coords[idx, 1], color=color_dict[label[:-8]], marker='o', markersize=3, alpha=0.5)\n",
    "        # Remove background grid and ticks for a cleaner look\n",
    "    plt.grid(False)\n",
    "\n",
    "    # Adjust layout to fit the legend outside\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])  # Leaves space for legend on the right\n",
    "    plt.savefig('combined_dataset_samples_and_tissue.pdf', dpi=600, bbox_inches=\"tight\")\n",
    "    plt.close() \n",
    "\n",
    "    # # Save the plot\n",
    "    # plt.savefig('marker_gene_clustering.pdf', dpi=600)\n",
    "    # plt.close()\n",
    "\n",
    "    # # Plot Leiden clustering\n",
    "    # sc.pl.umap(combined_adata, color=['leiden'], save='leiden_clustering.pdf')\n",
    "\n",
    "    # # Identify marker genes\n",
    "    # identify_marker_genes(combined_adata, annotation)\n",
    "\n",
    "def identify_marker_genes(adata, annotation):\n",
    "    sc.tl.rank_genes_groups(adata, annotation, method='wilcoxon') #Find marker genes by tissue instead of by leiden clustering (done earlier)\n",
    "    marker_genes = adata.uns['rank_genes_groups']['names']\n",
    "\n",
    "    # Get the top N genes for each cluster\n",
    "    n_top_genes = 5\n",
    "    top_genes = pd.DataFrame(marker_genes).iloc[:n_top_genes]\n",
    "\n",
    "    sc.pl.rank_genes_groups_dotplot(\n",
    "        adata,\n",
    "        groupby=annotation,  # Use tissue labels for grouping instead of 'leiden'\n",
    "        n_genes=4,\n",
    "        values_to_plot=\"logfoldchanges\", cmap='bwr', #changed from 'viridis'  \n",
    "        vmin=-4,\n",
    "        vmax=4,\n",
    "        min_logfoldchange=3,\n",
    "        colorbar_title='log fold change'\n",
    "    )\n",
    "    plt.savefig('marker_genes_by_tissue.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 14:27:30 - INFO - Starting Scanpy bulk to single-cell integration pipeline\n",
      "2025-03-17 14:27:30 - INFO - Bulk data: /private/groups/russelllab/jodie/wolbachia_induced_DE/scanpy_clustering/scanpy_objects/bulk_adata.h5ad\n",
      "2025-03-17 14:27:30 - INFO - Reference data: /private/groups/russelllab/jodie/wolbachia_induced_DE/scanpy_clustering/scanpy_objects/combined_germline_sg_trachea.h5ad\n",
      "2025-03-17 14:27:30 - INFO - Output directory: /private/groups/russelllab/jodie/wolbachia_induced_DE/wolbachia_induced_differentiation/scripts/celltype_clustering/claude/MNN_kNN_tree/embryo_atlas_germline\n",
      "2025-03-17 14:27:30 - INFO - Loading data files...\n",
      "2025-03-17 14:27:30 - INFO - Bulk dataset loaded: (24, 10957) (samples × genes)\n",
      "2025-03-17 14:27:30 - INFO - Reference dataset loaded: (3335, 10083) (cells × genes)\n",
      "2025-03-17 14:27:30 - INFO - Number of shared genes: 8325\n",
      "2025-03-17 14:27:30 - INFO - Preprocessing datasets...\n",
      "2025-03-17 14:27:31 - INFO - Using 8325 shared genes\n",
      "2025-03-17 14:27:34 - INFO - Concatenating 12 subsampled datasets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Log start of processing\n",
    "logger.info(\"Starting Scanpy bulk to single-cell integration pipeline\")\n",
    "logger.info(f\"Bulk data: {bulk_path}\")\n",
    "logger.info(f\"Reference data: {ref_path}\")\n",
    "logger.info(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# try:\n",
    "# Load and validate data\n",
    "bulk_adata, ref_adata = load_and_validate_data(bulk_path, ref_path)\n",
    "\n",
    "# Preprocess data\n",
    "bulk_processed, ref_processed = preprocess_data(bulk_adata, ref_adata, annotation_key)\n",
    "\n",
    "# Sample even cell types across the reference\n",
    "ref_processed=subsample_celltypes(ref_processed, annotation_key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 14:27:35 - INFO - Integrating datasets...\n",
      "2025-03-17 14:27:35 - INFO - Combined dataset shape: (804, 8325)\n",
      "2025-03-17 14:27:35 - INFO - Data is already normalized and log-transformed\n",
      "2025-03-17 14:27:35 - INFO - Applying MNN batch correction...\n",
      "2025-03-17 14:27:35 - INFO - MNN batch correction completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'anndata._core.anndata.AnnData'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute '_sanitize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m combined_adata \u001b[38;5;241m=\u001b[39m integrate_datasets(bulk_processed, ref_processed)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# combined_adata=combined_adata[0] #necesasry to extract the first element of the tuple of MNN corrected data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mplot_UMAP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_adata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m, in \u001b[0;36mplot_UMAP\u001b[0;34m(combined_adata, annotation)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot_UMAP\u001b[39m(combined_adata, annotation):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Perform UMAP\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# neighbors_rank(combined_adata)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Plot UMAP, save to file\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mumap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_adata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcombine-dataset.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Visualization\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     sc\u001b[38;5;241m.\u001b[39mpl\u001b[38;5;241m.\u001b[39mumap(combined_adata, color\u001b[38;5;241m=\u001b[39m[annotation], save\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined-tissue.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/scanpy_ipynb/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:691\u001b[0m, in \u001b[0;36mumap\u001b[0;34m(adata, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;129m@_wraps_plot_scatter\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;129m@_doc_params\u001b[39m(\n\u001b[1;32m    634\u001b[0m     adata_color_etc\u001b[38;5;241m=\u001b[39mdoc_adata_color_etc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    638\u001b[0m )\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mumap\u001b[39m(adata: AnnData, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Figure \u001b[38;5;241m|\u001b[39m Axes \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[Axes] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    640\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\\\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m    Scatter plot in UMAP basis.\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03m    tl.umap\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mumap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/scanpy_ipynb/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:143\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(adata, basis, color, mask_obs, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, marker, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m#####################\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Argument handling #\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m#####################\u001b[39;00m\n\u001b[1;32m    142\u001b[0m check_projection(projection)\n\u001b[0;32m--> 143\u001b[0m \u001b[43msanitize_anndata\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m basis_values \u001b[38;5;241m=\u001b[39m _get_basis(adata, basis)\n\u001b[1;32m    146\u001b[0m dimensions \u001b[38;5;241m=\u001b[39m _components_to_dimensions(\n\u001b[1;32m    147\u001b[0m     components, dimensions, projection\u001b[38;5;241m=\u001b[39mprojection, total_dims\u001b[38;5;241m=\u001b[39mbasis_values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    148\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/scanpy_ipynb/lib/python3.9/site-packages/scanpy/_utils/__init__.py:450\u001b[0m, in \u001b[0;36msanitize_anndata\u001b[0;34m(adata)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msanitize_anndata\u001b[39m(adata: AnnData) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    449\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform string annotations to categoricals.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m     \u001b[43madata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute '_sanitize'"
     ]
    }
   ],
   "source": [
    "# Integrate datasets\n",
    "combined_adata = integrate_datasets(bulk_processed, ref_processed)\n",
    "\n",
    "combined_adata=combined_adata[0] #necesasry to extract the first element of the tuple of MNN corrected data\n",
    "\n",
    "\n",
    "plot_UMAP(combined_adata, annotation_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 11:11:59 - INFO - Automatically determined k = 21 (sqrt(n) = 32, 10% of smallest class = 21)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'kNN_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     k \u001b[38;5;241m=\u001b[39m determine_optimal_k(ref_processed, annotation_key)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run kNN classification\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m results_df, annotated_adata \u001b[38;5;241m=\u001b[39m \u001b[43mkNN_classifier\u001b[49m(\n\u001b[1;32m      8\u001b[0m     combined_adata,\n\u001b[1;32m      9\u001b[0m     ref_label_key\u001b[38;5;241m=\u001b[39mannotation_key,\n\u001b[1;32m     10\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m     11\u001b[0m     num_permutations\u001b[38;5;241m=\u001b[39mnum_permutations\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Generate visualizations\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# annotated_adata = visualize_integration(annotated_adata, annotation_key, plots_dir)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Extract bulk annotations and save to files\u001b[39;00m\n\u001b[1;32m     18\u001b[0m bulk_samples \u001b[38;5;241m=\u001b[39m annotated_adata[annotated_adata\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbulk\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kNN_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Determine optimal k if not provided\n",
    "k = k_neighbors\n",
    "if k is None:\n",
    "    k = determine_optimal_k(ref_processed, annotation_key)\n",
    "\n",
    "# Run kNN classification\n",
    "results_df, annotated_adata = kNN_classifier(\n",
    "    combined_adata,\n",
    "    ref_label_key=annotation_key,\n",
    "    k=k,\n",
    "    num_permutations=num_permutations\n",
    ")\n",
    "\n",
    "# Generate visualizations\n",
    "# annotated_adata = visualize_integration(annotated_adata, annotation_key, plots_dir)\n",
    "\n",
    "# Extract bulk annotations and save to files\n",
    "bulk_samples = annotated_adata[annotated_adata.obs['dataset'] == 'bulk']\n",
    "bulk_annotations = bulk_samples.obs[[annotation_key]]\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(os.path.join(output_dir, 'bulk_classification_results.csv'), index=False)\n",
    "bulk_annotations.to_csv(os.path.join(output_dir, 'bulk_annotations.csv'))\n",
    "annotated_adata.write_h5ad(os.path.join(output_dir, 'annotated_data.h5ad'))\n",
    "\n",
    "logger.info(\"Integration pipeline completed successfully\")\n",
    "logger.info(f\"Results saved to {output_dir}\")\n",
    "\n",
    "# Plot UMAP\n",
    "logger.info(\"Plotting UMAP...\")\n",
    "# plot_UMAP(combined_adata, annotation_key)\n",
    "\n",
    "\n",
    "# except Exception as e:\n",
    "# logger.error(f\"Integration pipeline failed: {e}\")\n",
    "# import traceback\n",
    "# logger.error(traceback.format_exc())\n",
    "# sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {
      "image/png": {
       "height": 2334,
       "width": 2483
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc.pl.umap(combined_adata, color=[annotation_key], show=False)\n",
    "\n",
    "# Get the UMAP coordinates\n",
    "umap_coords = combined_adata.obsm['X_umap']\n",
    "\n",
    "# Get your sample labels from the data\n",
    "labels = combined_adata.obs['Sample']\n",
    "\n",
    "# Iterate over each point and add a label if it's not NA\n",
    "for idx, label in enumerate(labels):\n",
    "    if pd.notna(label):  # Check if the label is not NA\n",
    "\n",
    "        plt.plot(umap_coords[idx, 0], umap_coords[idx, 1], \n",
    "                color=color_dict[label[:-8]], \n",
    "                marker='o',            # '*' for star marker\n",
    "                markersize=10,          # Increase size for better visibility\n",
    "                markeredgecolor='white', # White outline\n",
    "                markeredgewidth=0.25,   # Width of the outline\n",
    "                alpha=1)    # Remove background grid and ticks for a cleaner look\n",
    "plt.grid(False)\n",
    "\n",
    "# Adjust layout to fit the legend outside\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])  # Leaves space for legend on the right\n",
    "plt.savefig(f'{output_dir}/combined_dataset_samples_and_tissue.pdf', dpi=600, bbox_inches=\"tight\")\n",
    "plt.show() \n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_enhanced_umap(combined_adata, annotation_key, plots_dir):\n",
    "    \"\"\"Generate enhanced UMAP visualizations that better show differences between groups.\"\"\"\n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Plot 1: Reference cells with bulk cells highlighted by sample group\n",
    "    ax = axes[0]\n",
    "    \n",
    "    # Plot reference cells in gray first\n",
    "    ref_mask = combined_adata.obs['dataset'] == 'reference'\n",
    "    ax.scatter(\n",
    "        combined_adata.obsm['X_umap'][ref_mask, 0],\n",
    "        combined_adata.obsm['X_umap'][ref_mask, 1],\n",
    "        c='lightgray', s=5, alpha=0.3, label='Reference Cells'\n",
    "    )\n",
    "    \n",
    "    # Get sample groups (assuming Sample column format like \"JW18DOX221117-1\")\n",
    "    bulk_mask = combined_adata.obs['dataset'] == 'bulk'\n",
    "    sample_groups = []\n",
    "    for sample_name in combined_adata.obs.loc[bulk_mask, 'Sample']:\n",
    "        # Extract the prefix (e.g., \"JW18DOX\", \"JW18wMel\", \"S2DOX\", \"S2wMel\")\n",
    "        if pd.notna(sample_name):\n",
    "            prefix = sample_name.split('221117')[0]  # Remove date and number suffix\n",
    "            sample_groups.append(prefix)\n",
    "        else:\n",
    "            sample_groups.append('Unknown')\n",
    "    \n",
    "    # Add Sample group as a new column\n",
    "    combined_adata.obs.loc[bulk_mask, 'SampleGroup'] = sample_groups\n",
    "    \n",
    "    # Plot bulk samples with colors based on their sample group\n",
    "    for group, color in color_dict.items():\n",
    "        group_mask = (combined_adata.obs['dataset'] == 'bulk') & (combined_adata.obs['SampleGroup'] == group)\n",
    "        ax.scatter(\n",
    "            combined_adata.obsm['X_umap'][group_mask, 0],\n",
    "            combined_adata.obsm['X_umap'][group_mask, 1],\n",
    "            c=color, s=100, alpha=0.9, label=f'{group}',\n",
    "            edgecolors='white', linewidths=0.5\n",
    "        )\n",
    "    \n",
    "    ax.set_title('UMAP - Samples Colored by Experimental Condition')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(False)\n",
    "    ax.set_xlabel('UMAP 1')\n",
    "    ax.set_ylabel('UMAP 2')\n",
    "    \n",
    "    # Plot 2: Reference cells colored by cell type, bulk samples as larger points\n",
    "    ax = axes[1]\n",
    "    \n",
    "    # Create a colormap for cell types\n",
    "    cell_types = combined_adata.obs[annotation_key].cat.categories\n",
    "    n_cell_types = len(cell_types)\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, n_cell_types))\n",
    "    \n",
    "    # Plot reference cells colored by cell type\n",
    "    for i, cell_type in enumerate(cell_types):\n",
    "        ct_mask = (combined_adata.obs['dataset'] == 'reference') & (combined_adata.obs[annotation_key] == cell_type)\n",
    "        ax.scatter(\n",
    "            combined_adata.obsm['X_umap'][ct_mask, 0],\n",
    "            combined_adata.obsm['X_umap'][ct_mask, 1],\n",
    "            c=[colors[i]], s=10, alpha=0.6, label=f'{cell_type}'\n",
    "        )\n",
    "    \n",
    "    # Plot bulk samples as larger points\n",
    "    for i, cell_type in enumerate(cell_types):\n",
    "        ct_mask = (combined_adata.obs['dataset'] == 'bulk') & (combined_adata.obs[annotation_key] == cell_type)\n",
    "        ax.scatter(\n",
    "            combined_adata.obsm['X_umap'][ct_mask, 0],\n",
    "            combined_adata.obsm['X_umap'][ct_mask, 1],\n",
    "            c=[colors[i]], s=150, alpha=1.0, edgecolors='black', linewidths=0.5\n",
    "        )\n",
    "    \n",
    "    ax.set_title(f'UMAP - Cell Types ({annotation_key})')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(False)\n",
    "    ax.set_xlabel('UMAP 1')\n",
    "    ax.set_ylabel('UMAP 2')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'enhanced_umap_visualization.pdf'), bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a visualization to verify KNN classification results\n",
    "    verify_knn_visualization(combined_adata, annotation_key, plots_dir)\n",
    "    \n",
    "    return combined_adata\n",
    "\n",
    "def verify_knn_visualization(combined_adata, annotation_key, plots_dir):\n",
    "    \"\"\"Create a visualization to verify KNN classification results for a few samples.\"\"\"\n",
    "    bulk_mask = combined_adata.obs['dataset'] == 'bulk'\n",
    "    ref_mask = combined_adata.obs['dataset'] == 'reference'\n",
    "    \n",
    "    # Get sample groups\n",
    "    sample_groups = combined_adata.obs.loc[bulk_mask, 'SampleGroup'].unique()\n",
    "    \n",
    "    # Select one sample from each group to visualize\n",
    "    selected_samples = []\n",
    "    for group in sample_groups:\n",
    "        group_samples = combined_adata.obs.loc[bulk_mask & (combined_adata.obs['SampleGroup'] == group)].index\n",
    "        if len(group_samples) > 0:\n",
    "            selected_samples.append(group_samples[0])\n",
    "    \n",
    "    # Create a figure with subplots for each selected sample\n",
    "    fig, axes = plt.subplots(len(selected_samples), 1, figsize=(12, 6*len(selected_samples)))\n",
    "    if len(selected_samples) == 1:\n",
    "        axes = [axes]  # Make axes iterable if only one subplot\n",
    "    \n",
    "    # For each selected sample\n",
    "    for i, sample_id in enumerate(selected_samples):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Get sample info\n",
    "        sample_idx = combined_adata.obs.index.get_loc(sample_id)\n",
    "        sample_group = combined_adata.obs.loc[sample_id, 'SampleGroup']\n",
    "        predicted_label = combined_adata.obs.loc[sample_id, annotation_key]\n",
    "        \n",
    "        # Plot all reference cells as background\n",
    "        ax.scatter(\n",
    "            combined_adata.obsm['X_umap'][ref_mask, 0],\n",
    "            combined_adata.obsm['X_umap'][ref_mask, 1],\n",
    "            c='lightgray', s=5, alpha=0.2\n",
    "        )\n",
    "        \n",
    "        # Plot cells of the predicted cell type\n",
    "        pred_mask = ref_mask & (combined_adata.obs[annotation_key] == predicted_label)\n",
    "        ax.scatter(\n",
    "            combined_adata.obsm['X_umap'][pred_mask, 0],\n",
    "            combined_adata.obsm['X_umap'][pred_mask, 1],\n",
    "            c='blue', s=20, alpha=0.5, label=f'Reference {predicted_label} cells'\n",
    "        )\n",
    "        \n",
    "        # Plot the sample itself\n",
    "        ax.scatter(\n",
    "            combined_adata.obsm['X_umap'][sample_idx, 0],\n",
    "            combined_adata.obsm['X_umap'][sample_idx, 1],\n",
    "            c=color_dict[sample_group], s=200, alpha=1.0, \n",
    "            edgecolors='black', linewidths=1.0,\n",
    "            label=f'{sample_id} ({sample_group})'\n",
    "        )\n",
    "        \n",
    "        # Get the K nearest neighbors for this sample from the results file\n",
    "        # Note: This would need the results DataFrame to be passed as an argument\n",
    "        # For visualization purposes, we'll just use the 10 nearest reference cells based on UMAP distance\n",
    "        \n",
    "        # Calculate distances in UMAP space\n",
    "        sample_umap = combined_adata.obsm['X_umap'][sample_idx]\n",
    "        ref_umaps = combined_adata.obsm['X_umap'][ref_mask]\n",
    "        \n",
    "        # Calculate Euclidean distances\n",
    "        distances = np.sqrt(np.sum((ref_umaps - sample_umap)**2, axis=1))\n",
    "        \n",
    "        # Get indices of 10 nearest neighbors\n",
    "        nearest_indices = np.argsort(distances)[:10]\n",
    "        nearest_indices = np.where(ref_mask)[0][nearest_indices]\n",
    "        \n",
    "        # Plot nearest neighbors\n",
    "        ax.scatter(\n",
    "            combined_adata.obsm['X_umap'][nearest_indices, 0],\n",
    "            combined_adata.obsm['X_umap'][nearest_indices, 1],\n",
    "            c='red', s=80, alpha=0.7, \n",
    "            edgecolors='black', linewidths=0.5,\n",
    "            marker='*', label='Nearest neighbors (UMAP space)'\n",
    "        )\n",
    "        \n",
    "        ax.set_title(f'Sample: {sample_id} - Group: {sample_group} - Predicted: {predicted_label}')\n",
    "        ax.legend(loc='upper right')\n",
    "        ax.grid(False)\n",
    "        ax.set_xlabel('UMAP 1')\n",
    "        ax.set_ylabel('UMAP 2')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'knn_verification.pdf'), bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_enhanced_umap(combined_adata, annotation_key, plots_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_knn_visualization(combined_adata, annotation_key, plots_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scanpy_ipynb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
